

# Energy Monitoring System - Setup Guide

Sistema de monitoreo de energÃ­a con generaciÃ³n automÃ¡tica de eventos, procesamiento mediante Kafka y persistencia en PostgreSQL.

## ğŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Arquitectura](#arquitectura)
- [Requisitos Previos](#requisitos-previos)
- [InstalaciÃ³n](#instalaciÃ³n)
- [ConfiguraciÃ³n](#configuraciÃ³n)
- [EjecuciÃ³n](#ejecuciÃ³n)
- [Uso de la API REST](#uso-de-la-api-rest)
- [VisualizaciÃ³n con DBeaver](#visualizaciÃ³n-con-dbeaver)
- [Kafka UI](#kafka-ui)
- [Troubleshooting](#troubleshooting)
- [Estructura del Proyecto](#estructura-del-proyecto)

---

## ğŸ¯ CaracterÃ­sticas

- âœ… **GeneraciÃ³n automÃ¡tica de eventos**: 30 eventos cada 5 minutos
- âœ… **IntegraciÃ³n con Kafka**: Producer y Consumer
- âœ… **Persistencia en PostgreSQL**: Con TimescaleDB y PostGIS
- âœ… **API REST**: 3 endpoints para consultar eventos
- âœ… **VisualizaciÃ³n**: DBeaver, pgAdmin, Kafka UI
- âœ… **Hot Reload**: Desarrollo con Air
- âœ… **Migraciones**: Goose para versionado de DB
- âœ… **Swagger**: DocumentaciÃ³n automÃ¡tica de API

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ENERGY MONITORING SYSTEM                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Event Generator    â”‚  â† Genera 30 eventos cada 5 min
â”‚  (Go Application)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Produce eventos
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka Broker      â”‚  â† Topic: "intake"
â”‚   (Port 9092)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Consume eventos
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Intake Handler     â”‚  â† Procesa y guarda
â”‚  (Kafka Consumer)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ INSERT
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL        â”‚  â† Tabla: events
â”‚   (Port 5432)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ SELECT
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    REST API         â”‚    DBeaver      â”‚   pgAdmin    â”‚
â”‚  (Port 9000)        â”‚  (Port 5432)    â”‚  (Port 5050) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Requisitos Previos

### Software Necesario

| Software | VersiÃ³n MÃ­nima | VerificaciÃ³n |
|----------|----------------|--------------|
| Go | 1.24+ | `go version` |
| Docker | 20.10+ | `docker --version` |
| Docker Compose | 2.0+ | `docker compose version` |
| Make | 4.0+ | `make --version` |
| Git | 2.0+ | `git --version` |

### Herramientas Opcionales

- **DBeaver**: Para visualizaciÃ³n de datos en PostgreSQL
- **Postman/cURL**: Para probar la API REST
- **Air**: Hot reload (se instala automÃ¡ticamente)

---

## ğŸš€ InstalaciÃ³n

### Paso 1: Clonar el Repositorio

```bash
git clone <repository-url>
cd template-monitoryn-energy-main
```

### Paso 2: Instalar Herramientas de Desarrollo

```bash
make install-dev-tools
```

Este comando instala:
- âœ… Air (hot reload)
- âœ… Modd (file watcher)
- âœ… Goose (migraciones)
- âœ… Atlas (generaciÃ³n de migraciones)
- âœ… Swag (Swagger docs)

### Paso 3: Configurar Variables de Entorno

```bash
cp .env.example .env
```

Verifica que `.env` contenga:

```bash
# Server
PORT=9000
ENVIRONMENT=dev

# Database
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=monitoring_energy
DATABASE_USER=postgres
DATABASE_PASSWORD=postgres

# Kafka - IMPORTANTE: CONSUMER_TOPIC debe ser "intake"
LIST_KAFKA_BROKERS=localhost:9092
CONSUMER_GROUP=monitoring-energy-group
CONSUMER_TOPIC=intake
PRODUCER_TOPIC=events.output
```

âš ï¸ **IMPORTANTE**: `CONSUMER_TOPIC` debe ser `intake` (no `events.default`)

### Paso 4: Iniciar Servicios Docker

```bash
make docker-up
```

O manualmente:

```bash
docker compose up -d
```

Esto iniciarÃ¡:
- âœ… PostgreSQL (puerto 5432)
- âœ… pgAdmin (puerto 5050)
- âœ… Kafka (puerto 9092)
- âœ… Zookeeper (puerto 2181)
- âœ… Kafka UI (puerto 8080)

### Paso 5: Verificar Servicios

```bash
docker compose ps
```

Todos los servicios deben mostrar estado `Up`:

```
NAME                         STATUS
monitoring-energy-db         Up (healthy)
monitoring-energy-kafka      Up
monitoring-energy-zookeeper  Up
monitoring-energy-kafka-ui   Up
monitoring-energy-pgadmin    Up
```

### Paso 6: Verificar Conectividad

```bash
# PostgreSQL
docker exec monitoring-energy-db psql -U postgres -c "SELECT version();"

# Kafka
docker exec monitoring-energy-kafka kafka-topics --bootstrap-server localhost:9092 --list
```

---

## âš™ï¸ ConfiguraciÃ³n

### MigraciÃ³n de Base de Datos

Las migraciones se ejecutan automÃ¡ticamente al iniciar la aplicaciÃ³n, pero tambiÃ©n puedes ejecutarlas manualmente:

```bash
# Aplicar todas las migraciones
make goose-up

# Ver estado de migraciones
make goose-status

# Rollback Ãºltima migraciÃ³n
make goose-down
```

### Verificar Tabla de Eventos

```bash
docker exec monitoring-energy-db psql -U postgres -d monitoring_energy \
  -c "\d events"
```

DeberÃ­as ver:

```
                Table "public.events"
   Column    |           Type           | Nullable
-------------+--------------------------+----------
 id          | uuid                     | not null
 event_type  | character varying(100)   | not null
 source      | character varying(255)   |
 data        | text                     |
 metadata    | text                     |
 created_at  | timestamp with time zone |
```

---

## ğŸƒ EjecuciÃ³n

### OpciÃ³n 1: Development con Hot Reload (Recomendado)

```bash
make dev
```

Esto:
- âœ… Inicia la aplicaciÃ³n con Air
- âœ… Recarga automÃ¡ticamente cuando cambias cÃ³digo
- âœ… Genera documentaciÃ³n Swagger
- âœ… Muestra logs en tiempo real

### OpciÃ³n 2: EjecuciÃ³n Directa

```bash
go run main.go
```

### OpciÃ³n 3: Build y Ejecutar

```bash
make build
./bin/monitoring-energy-service
```

### Verificar que la AplicaciÃ³n EstÃ¡ Funcionando

```bash
# Health check
curl http://localhost:9000/healthz

# DeberÃ­a responder: 200 OK
```

---

## ğŸ“¡ Uso de la API REST

### Endpoints Disponibles

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| GET | `/api/v1/events` | Lista todos los eventos |
| GET | `/api/v1/events/:id` | Obtiene un evento por UUID |
| GET | `/api/v1/events/type/:type` | Filtra eventos por tipo |
| GET | `/healthz` | Health check |
| GET | `/readyz` | Readiness check |

### Ejemplos de Uso

#### 1. Listar Todos los Eventos

```bash
curl http://localhost:9000/api/v1/events
```

**Respuesta:**
```json
[
  {
    "id": "550e8400-e29b-41d4-a716-446655440000",
    "event_type": "power_reading",
    "source": "Solar Farm Alpha",
    "data": "{\"plant_id\":\"plant-1\",\"power_generated_mw\":523.45,...}",
    "created_at": "2026-01-01T16:42:00Z"
  }
]
```

#### 2. Obtener Evento por ID

```bash
curl http://localhost:9000/api/v1/events/550e8400-e29b-41d4-a716-446655440000
```

#### 3. Filtrar por Tipo

```bash
# Solo power_reading
curl http://localhost:9000/api/v1/events/type/power_reading

# Solo alerts
curl http://localhost:9000/api/v1/events/type/alert

# Solo efficiency_report
curl http://localhost:9000/api/v1/events/type/efficiency_report
```

#### 4. Formatear Respuesta con jq

```bash
curl -s http://localhost:9000/api/v1/events | jq '.[0:5]'
```

### Swagger UI

Accede a la documentaciÃ³n interactiva:

```
http://localhost:9000/swagger/index.html
```

---

## ğŸ—„ï¸ VisualizaciÃ³n con DBeaver

### InstalaciÃ³n de DBeaver

**Ubuntu/Debian:**
```bash
sudo snap install dbeaver-ce
```

**Otras plataformas:**
Descarga desde https://dbeaver.io/download/

### Configurar ConexiÃ³n

1. Abre DBeaver
2. Click en **Nueva ConexiÃ³n** â†’ **PostgreSQL**
3. Configura:

```
Host:          localhost
Puerto:        5432
Base de datos: monitoring_energy
Usuario:       postgres
ContraseÃ±a:    postgres
```

4. Click **Test Connection**
5. Click **Finish**

### Consultas Ãštiles

#### Ver Ãšltimos 50 Eventos

```sql
SELECT
    id,
    event_type,
    source,
    created_at,
    LEFT(data, 100) as data_preview
FROM events
ORDER BY created_at DESC
LIMIT 50;
```

#### Contar Eventos por Tipo

```sql
SELECT
    event_type,
    COUNT(*) as total
FROM events
GROUP BY event_type
ORDER BY total DESC;
```

#### Eventos por Planta

```sql
SELECT
    source,
    COUNT(*) as total_eventos
FROM events
GROUP BY source
ORDER BY total_eventos DESC;
```

#### Eventos de los Ãšltimos 10 Minutos

```sql
SELECT
    event_type,
    source,
    created_at
FROM events
WHERE created_at > NOW() - INTERVAL '10 minutes'
ORDER BY created_at DESC;
```

#### Extraer Datos JSON

```sql
SELECT
    event_type,
    source,
    data::json->>'power_generated_mw' as power_mw,
    data::json->>'efficiency_percent' as efficiency,
    created_at
FROM events
WHERE event_type = 'power_reading'
LIMIT 20;
```

---

## ğŸ“Š Kafka UI

Accede a la interfaz web de Kafka:

```
http://localhost:8080
```

### Ver Mensajes en el Topic "intake"

1. Navega a **Topics** â†’ **intake**
2. Click en **Messages**
3. VerÃ¡s los eventos en tiempo real
4. Puedes filtrar, buscar y exportar mensajes

### Crear Nuevo Topic (Opcional)

```bash
docker exec monitoring-energy-kafka \
  kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic nuevo-topic \
  --partitions 3 \
  --replication-factor 1
```

---

## ğŸ› Troubleshooting

### Problema: "Connection refused" al conectar a Kafka

**SoluciÃ³n:**
```bash
# Verificar que Kafka estÃ¡ corriendo
docker compose ps

# Ver logs de Kafka
docker compose logs kafka

# Reiniciar Kafka
docker compose restart kafka
```

### Problema: "Subscribed topic not available: events.default"

**Causa:** CONSUMER_TOPIC incorrecto en `.env`

**SoluciÃ³n:**
```bash
# Editar .env
CONSUMER_TOPIC=intake  # DEBE ser "intake", NO "events.default"

# Reiniciar aplicaciÃ³n
```

### Problema: "Error saving event to database: invalid input syntax for type json"

**Causa:** Columna `data` configurada como JSONB en vez de TEXT

**SoluciÃ³n:**
```bash
# Rollback y reaplica migraciÃ³n
make goose-down
make goose-up
```

La migraciÃ³n correcta usa `TEXT`:
```sql
CREATE TABLE "events" (
  ...
  "data" text NULL,  -- TEXT, no JSONB
  ...
);
```

### Problema: Puerto 9000 ya en uso

**SoluciÃ³n:**
```bash
# Encontrar proceso usando puerto 9000
lsof -ti:9000

# Matar proceso
kill -9 $(lsof -ti:9000)

# O cambiar puerto en .env
PORT=9001
```

### Problema: No se generan eventos

**VerificaciÃ³n:**
```bash
# Ver logs de la aplicaciÃ³n
tail -f /tmp/app.log

# DeberÃ­as ver:
# "Starting Event Generator - will send 30 messages every 5 minutes"
# "Event 1 sent: PlantID=plant-1, Type=power_reading, Power=523.45MW"
```

**SoluciÃ³n:**
- Verifica que `go c.EventGenerator.Start()` estÃ© en main.go
- Confirma que el generador se inicializa en container.go

### Problema: Eventos no se guardan en PostgreSQL

**DiagnÃ³stico:**
```bash
# Ver logs del IntakeHandler
grep "saved to database" /tmp/app.log

# Verificar eventos en DB
docker exec monitoring-energy-db psql -U postgres -d monitoring_energy \
  -c "SELECT COUNT(*) FROM events;"
```

**SoluciÃ³n:**
- Verifica que IntakeHandler recibe EventRepository
- Confirma que CONSUMER_TOPIC es "intake"
- Revisa logs de errores de PostgreSQL

### Logs Ãštiles

```bash
# Logs de la aplicaciÃ³n Go
tail -f /tmp/app.log

# Logs de PostgreSQL
docker compose logs db

# Logs de Kafka
docker compose logs kafka

# Logs de todos los servicios
docker compose logs -f
```

### Problema: "failed to read dockerfile: open Dockerfile: no such file or directory"

**Causa:** Al ejecutar `docker compose up -d` el servicio `api` intenta construir usando un `Dockerfile` en la raÃ­z del proyecto, pero en este repositorio solo existe `db/Dockerfile`.

**Soluciones:**

- Levantar los servicios sin construir la API (recomendado si ejecutas la app localmente con `go run`):

```bash
docker compose up -d
```

- Incluir y construir la API con el perfil `dev` (solo si quieres que Compose construya/ejecute la API en contenedor):

```bash
docker compose --profile dev up -d
```

- Alternativa: crear un `Dockerfile` para la API en la raÃ­z del repo o modificar `docker-compose.yml` para apuntar a la ruta correcta del `Dockerfile`.

Si eliges usar el contenedor `api`, asegÃºrate de que el `Dockerfile` exista en la ruta indicada o ajusta `build.context`/`dockerfile` en [docker-compose.yml](docker-compose.yml).

---

## ğŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ atlasloader/          # Cargador de entidades para Atlas
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ Dockerfile            # PostgreSQL con PostGIS y TimescaleDB
â”‚   â””â”€â”€ init-db.sql           # Script de inicializaciÃ³n
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ event_generator.go     # ğŸ†• Generador de eventos (30 cada 5 min)
â”‚   â”‚   â”œâ”€â”€ intake_handler.go      # ğŸ”§ Consumer de Kafka (guarda en DB)
â”‚   â”‚   â””â”€â”€ kafka_service.go       # Servicio de Kafka
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”‚   â”œâ”€â”€ event_entity.go    # ğŸ†• Entidad de eventos
â”‚   â”‚   â”‚   â””â”€â”€ energy_plant_entity.go
â”‚   â”‚   â””â”€â”€ ports/
â”‚   â”‚       â”œâ”€â”€ input/             # Interfaces de servicios
â”‚   â”‚       â””â”€â”€ output/
â”‚   â”‚           â””â”€â”€ interfaces.go  # ğŸ”§ EventRepositoryInterface
â”‚   â””â”€â”€ infrastructure/
â”‚       â”œâ”€â”€ adapters/
â”‚       â”‚   â”œâ”€â”€ repositories/
â”‚       â”‚   â”‚   â””â”€â”€ event_repo.go  # ğŸ†• Repositorio de eventos
â”‚       â”‚   â”œâ”€â”€ rest/
â”‚       â”‚   â”‚   â”œâ”€â”€ event_handlers.go  # ğŸ†• Handlers REST para eventos
â”‚       â”‚   â”‚   â””â”€â”€ router.go          # ğŸ”§ Rutas (+ /api/v1/events)
â”‚       â”‚   â””â”€â”€ kafka/
â”‚       â”œâ”€â”€ conf/                  # ConfiguraciÃ³n
â”‚       â””â”€â”€ container/
â”‚           â””â”€â”€ container.go       # ğŸ”§ DI Container (+ EventRepo y Generator)
â”œâ”€â”€ migrations/
â”‚   â””â”€â”€ 20260101201616_create_events_table.sql  # ğŸ†• MigraciÃ³n tabla events
â”œâ”€â”€ .env                          # ğŸ”§ Variables de entorno (CONSUMER_TOPIC=intake)
â”œâ”€â”€ docker-compose.yml            # ğŸ”§ Servicios Docker
â”œâ”€â”€ main.go                       # ğŸ”§ Punto de entrada (+ EventGenerator.Start())
â”œâ”€â”€ CHANGES.md                    # ğŸ†• DocumentaciÃ³n de cambios
â””â”€â”€ README_SETUP.md               # ğŸ†• Esta guÃ­a

ğŸ†• = Archivo nuevo
ğŸ”§ = Archivo modificado
```

---

## ğŸ” Credenciales por Defecto

### PostgreSQL
```
Host:     localhost
Puerto:   5432
DB:       monitoring_energy
Usuario:  postgres
Password: postgres
```

### pgAdmin
```
URL:      http://localhost:5050
Email:    admin@admin.com
Password: admin
```

### Kafka
```
Broker:   localhost:9092
Topic:    intake
UI:       http://localhost:8080
```

---

## ğŸ§ª Testing

### Test de IntegraciÃ³n Completo

```bash
# 1. Iniciar servicios
make docker-up

# 2. Ejecutar aplicaciÃ³n
make dev

# 3. Esperar 10 segundos para que se generen eventos

# 4. Verificar eventos en Kafka UI
open http://localhost:8080

# 5. Verificar eventos en PostgreSQL
docker exec monitoring-energy-db psql -U postgres -d monitoring_energy \
  -c "SELECT COUNT(*) FROM events;"

# 6. Verificar API REST
curl http://localhost:9000/api/v1/events | jq '. | length'

# 7. Verificar tipos de eventos
curl http://localhost:9000/api/v1/events/type/power_reading | jq '. | length'
```

**Resultado esperado:**
- âœ… Kafka UI muestra mensajes en topic "intake"
- âœ… PostgreSQL tiene 30+ eventos
- âœ… API REST retorna eventos en JSON
- âœ… Filtros por tipo funcionan

---

## ğŸ“ˆ MÃ©tricas de Performance

**Sistema en ejecuciÃ³n estable:**
- **Eventos/minuto:** 6 (30 eventos cada 5 min)
- **Latencia Kafka â†’ PostgreSQL:** <100ms
- **Latencia API REST:** <50ms
- **Uso de memoria:** ~150MB (app Go)
- **TamaÃ±o promedio evento:** ~300 bytes

---

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una branch: `git checkout -b feature/nueva-funcionalidad`
3. Commit cambios: `git commit -am 'Add nueva funcionalidad'`
4. Push a la branch: `git push origin feature/nueva-funcionalidad`
5. Abre un Pull Request

---

## ğŸ“ Comandos Ãštiles

```bash
# Desarrollo
make dev              # Correr con hot reload
make dev-modd         # Correr con Modd
make run              # Correr sin hot reload
make build            # Compilar binario

# Docker
make docker-up        # Iniciar servicios
make docker-down      # Detener servicios
docker compose logs -f  # Ver logs en tiempo real

# Migraciones
make migrate-create name=nombre_migracion
make goose-up         # Aplicar migraciones
make goose-down       # Rollback
make goose-status     # Estado

# Testing
make test             # Correr tests
go test ./...         # Tests de todos los paquetes

# DocumentaciÃ³n
make swagger          # Generar Swagger docs
```

---

## ğŸ“ Soporte

**DocumentaciÃ³n adicional:**
- `CHANGES.md` - Detalle completo de cambios
- `README.md` - DocumentaciÃ³n original del template
- Swagger UI: http://localhost:9000/swagger/index.html

**Issues:**
Reporta problemas en el repositorio de GitHub

---

## ğŸ“„ Licencia

[Especificar licencia]

---

**âœ¨ Â¡Sistema listo para usar! Disfruta monitoreando energÃ­a con Kafka y PostgreSQL.**
